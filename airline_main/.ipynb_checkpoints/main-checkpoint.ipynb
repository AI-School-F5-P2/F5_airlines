{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTACION DE LIBRERIAS Y LECTURA DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías básicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import math\n",
    "\n",
    "# Librerías de visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(style=\"whitegrid\",font_scale=1, palette=\"pastel\")\n",
    "\n",
    "#Libreria para separacion de datos train y test\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, MinMaxScaler, FunctionTransformer, PowerTransformer\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    " \n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, MinMaxScaler, FunctionTransformer, PowerTransformer\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "\n",
    "\n",
    "# Librerias a usar para el modelo de machine learning\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_hist_gradient_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag que indica, cuando es True, que es la última vez que se entrena al modelo definitivo y se puede guardar\n",
    "save_pickle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformador personalizado que realiza la corrección de Camel Case\n",
    "class CamelCaseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[self.column_name] = X_copy[self.column_name].apply(lambda x: 'Disloyal Customer' if x == 'disloyal Customer' else x)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function que facilita la exploración básica del dataset\n",
    "def summary(df):\n",
    "    total_values = df.shape[0]\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percentage = (missing_data / total_values) * 100\n",
    "    print(f\"Dataset has {df.shape[1]} features and {df.shape[0]} rows.\")    \n",
    "    summary = pd.DataFrame(index=df.columns)\n",
    "    summary[\"Unique\"] = df.nunique().values\n",
    "    summary[\"Missing\"] = df.isnull().sum().values\n",
    "    summary['Missing %'] = ((missing_data / total_values) * 100).round(2)\n",
    "    summary[\"Duplicated\"] = df.duplicated().sum()\n",
    "    summary[\"Types\"] = df.dtypes\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura del dataset\n",
    "df = pd.read_csv(\"airline_passenger_satisfaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura Pandas para mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NULOS E IMPUTACION DE NULOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se mira información del dataset: columnas 25, filas 103903, y solo la columna Arrival Delay in Minutes tiene nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se rectifica que solo haya una columna con datos nulos efectivamente solo hay en la columna Arrival Delay in Minutes **310 datos nulos**, posteriormente se decidirá que hacer con estos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones**\n",
    "\n",
    "- Columnas Unnamed, id no creo que sean importantes y se podrían eliminar. Además tienen una cardinalidad muy alta\n",
    "- La columna Baggage handlingtiene 5 valores en vez de 6 como todas las demás. Empieza en 1 en vez de 0\n",
    "- Arrival Delay in Minutes es la única que es flotante pasarla a int.\n",
    "- Arrival Delay in Minutes es la única que tiene missign values = 310, un 0.3% Muy poquito.Imputamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Revisamos los valores unicos de la columna \"Arrival Delay in Minutes\" para ver si se podia pasar de float a int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utiliza el método unique() para obtener todos los valores únicos\n",
    "unique_values = df['Arrival Delay in Minutes'].unique()\n",
    "\n",
    "# Muestra todos los valores únicos en la columna 'Arrival Delay in Minutes'\n",
    "#for value in unique_values:\n",
    "    #print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para llenar los valores nulos con la media: (MIRAR SI SE IMPUTAN CON MEDIA O MEDIANA)\n",
    "df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].fillna(df['Arrival Delay in Minutes'].mean())\n",
    "\n",
    "# Para eliminar las filas con valores nulos\n",
    "#df.dropna(subset=['Arrival Delay in Minutes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Arrival Delay in Minutes'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La columna 'Arrival Delay in Minutes' se puede pasar a int ya que no tiene valores que se consideren decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para convertir una columna de tipo float a int \n",
    "df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Arrival Delay in Minutes'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE BORRAN COLUMNAS QUE NO SIRVEN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna_a_borrar = ['Unnamed: 0', \"id\"]\n",
    "df = df.drop(columna_a_borrar, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "## Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df, x='satisfaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opiniones_neutral_or_dissatisfied =(df['satisfaction'] == 'neutral or dissatisfied').sum()\n",
    "# Imprimir la suma de opiniones \"neutral or dissatisfied\"\n",
    "print(\"Suma de opiniones 'neutral or dissatisfied':\", opiniones_neutral_or_dissatisfied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opiniones_satisfied=(df['satisfaction'] == 'satisfied').sum()\n",
    "# Imprimir la suma de opiniones \"satisfied\"\n",
    "print(\"Suma de opiniones 'satisfied':\",opiniones_satisfied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La variable esta balanceada, de momento se puede dejar asi, en caso de que estuviese desbalanceada se aplicarian tecnicas para balancear los datos y que el modelo funcionara mucho mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAFICA DE SERVICIOS DE LA AEROLINEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "services = [\"Inflight wifi service\", \"Departure/Arrival time convenient\", \"Ease of Online booking\", 'Gate location', 'Food and drink', \n",
    "            'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling',\n",
    "            'Checkin service', 'Inflight service', 'Cleanliness']\n",
    "\n",
    "# Ajustar el tamaño de la figura\n",
    "plt.figure(figsize=(12, 30))  # Aumenta el valor 30 para adaptarlo a la cantidad de subplots que tengas\n",
    "\n",
    "for idx, column in enumerate(services):\n",
    "    plt.subplot(len(services), 1, idx+1)\n",
    "    sns.countplot(x=column, hue=\"satisfaction\", data=df, palette=[\"#4e79a7\", \"#f28e2b\"])\n",
    "    plt.legend(loc='center', bbox_to_anchor=(1.2, 0.5))\n",
    "\n",
    "# Ajustar la disposición de las subtramas\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE VARIABLES NUMERICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Age\",\"Flight Distance\",\"Inflight wifi service\",\"Departure/Arrival time convenient\",\"Ease of Online booking\",\n",
    "                 \"Gate location\",\"Food and drink\",\"Online boarding\",\"Seat comfort\",\"Inflight entertainment\",\"On-board service\",\n",
    "                 \"Leg room service\",\"Baggage handling\",\"Checkin service\",\"Inflight service\",\"Cleanliness\",\"Departure Delay in Minutes\",\n",
    "                 \"Arrival Delay in Minutes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE GRAFICAN OUTLIERS DE TODAS LAS COLUMNAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_rows, n_cols = math.ceil(len(num_cols) / 2), 2\n",
    "fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 5 * n_rows))\n",
    "i = 0\n",
    "\n",
    "for num_col in num_cols:\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    sns.boxplot(data=df, x=num_col, y=\"satisfaction\", ax=ax[row, col])\n",
    "    ax[row, col].set_xlabel(num_col, fontsize=12)\n",
    "    ax[row, col].set_ylabel('Satisfaction', fontsize=12)\n",
    "    i += 1\n",
    "\n",
    "# Ajusta la disposición de los subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra los gráficos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALISIS DE COLUMNA \"AGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.histplot(data=df, x=\"Age\",  hue='satisfaction')\n",
    "plt.title('Age Feature Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Intentamos hacer graficos de barras para visualizar si las respuestas estan en una desigualdad alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calcula el número de filas y columnas para organizar los subplots\n",
    "n_rows, n_cols = math.ceil(len(num_cols) / 2), 2\n",
    "\n",
    "# Crea la figura y los ejes de los subplots\n",
    "fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 5 * n_rows))\n",
    "i = 0\n",
    "\n",
    "for num_col in num_cols:\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    sns.barplot(data=df, x=\"satisfaction\", y=num_col, ax=ax[row, col])\n",
    "    ax[row, col].set_xlabel(\"Satisfaction\", fontsize=12)\n",
    "    ax[row, col].set_ylabel(num_col, fontsize=12)\n",
    "    i += 1\n",
    "\n",
    "# Ajusta la disposición de los subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra los gráficos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CamelCase para `Customer Type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Loyal Customer\n",
       "1    disloyal Customer\n",
       "2       Loyal Customer\n",
       "3       Loyal Customer\n",
       "4       Loyal Customer\n",
       "Name: Customer Type, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Customer Type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar solo 'disloyal Customer' a 'Disloyal Customer'. Acordarme de ponerlo en el pipeline\n",
    "df.loc[df['Customer Type'] == 'disloyal Customer', 'Customer Type'] = 'Disloyal Customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customer Type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Seat comfort\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Inflight wifi service\"]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPA DE CORRELACION CON COLUMNAS NUMERICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacion_numericas = df[num_cols].corr()\n",
    "\n",
    "# Generamos una máscara para no duplicar los valores\n",
    "mask = np.triu(np.ones_like(correlacion_numericas, dtype=bool))\n",
    "#sns.heatmap(correlacion_numericas , mask = mask, annot =True , linewidth =0.2)\n",
    "\n",
    "# Crear el heatmap\n",
    "plt.figure(figsize=(15, 10))  # Ajusta el tamaño de la figura, puede ponerse o no.10,8\n",
    "#sns.heatmap(correlacion_numericas , mask = mask, annot =True , linewidth =0.2)\n",
    "sns.heatmap(correlacion_numericas,  mask = mask, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.2) # lw= 0.5\n",
    "plt.title('Heatmap de Correlación entre Columnas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE VARIABLES CATEGORICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisamos cuantas y cuales columnas categoricas hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols =[column for column, count in dict(df.nunique()).items()\n",
    "             if (df[column].dtype==\"O\") & (count<10)]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos las columnas con sus datos categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener categorías únicas (incluyendo valores nulos) de las columnas deseadas\n",
    "categorias_por_columna = {}\n",
    "for columna in cat_cols:\n",
    "    categorias = df[columna].unique()\n",
    "    categorias = [str(cat) if not pd.isnull(cat) else 'NaN' for cat in categorias]\n",
    "    categorias_por_columna[columna] = categorias\n",
    "\n",
    "# Mostrar las categorías en una tabla usando tabulate\n",
    "tabla = []\n",
    "for columna, categorias in categorias_por_columna.items():\n",
    "    tabla.append([columna, \", \".join(categorias)])\n",
    "\n",
    "tabla_formateada = tabulate(tabla, headers=[\"Columna\", \"Datos Categorícos (con Nulos)\"], tablefmt=\"grid\")\n",
    "print(tabla_formateada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZAMOS CON GRAFICO DE BARRAS LAS VARIABLES CATEGORICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el número de filas y columnas para organizar los subplots\n",
    "n_rows, n_cols = math.ceil(len(cat_cols) / 2), 2\n",
    "\n",
    "# Crea la figura y los ejes de los subplots\n",
    "fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 5 * n_rows))\n",
    "i = 0\n",
    "\n",
    "for var_cat in cat_cols:\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    sns.countplot(data=df, x=var_cat, hue=\"satisfaction\", ax=ax[row, col])\n",
    "    ax[row, col].set_xlabel(var_cat, fontsize=12)\n",
    "    ax[row, col].set_ylabel('Count', fontsize=12)\n",
    "    i += 1\n",
    "\n",
    "# Ajusta la disposición de los subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra los gráficos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTLIERS\n",
    "\n",
    "LAS SIGUIENTES LINEAS DE CODIGO SE USARÁN PARA BUSCAR OUTLIERS Y BORRARLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df[\"Flight Distance\"].mean()\n",
    "std = df[\"Flight Distance\"].std()\n",
    "\n",
    "threshold = 3 * std\n",
    "\n",
    "outliers = df[abs(df[\"Flight Distance\"] - mean) > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=outliers.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE PROCESAMIENTO: DIVISION DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La siguiente funcion se usará cuando el modelo ya esté entrenado y es para medir la capacidad del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columnas = df.columns.tolist()\n",
    "columnas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir a int\n",
    "def to_int(series):\n",
    "    return series.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir a Camel Case\n",
    "def camel_case(text):\n",
    "    words = text.split()\n",
    "    camel_case_text = ''.join([word.capitalize() for word in words])\n",
    "    return camel_case_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(model, X, y, flag):\n",
    "    \n",
    "    \n",
    "    #TRANSFORMADORES\n",
    "    # Transformador para la columna 'Arrival Delay in Minutes'\n",
    "    delay_transformer = FunctionTransformer(func=to_int)\n",
    "    \n",
    "    # Transformador para la columna 'Customer Type' para CamelCase\n",
    "    customer_transformer = FunctionTransformer(func=camel_case)\n",
    "        \n",
    "    \n",
    "    \n",
    "    num_transformer = Pipeline(steps=[\n",
    "    #('delay_to_int', delay_transformer),      \n",
    "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "    ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        #('correct_disloyal', customer_transformer(column_name='Customer Type')),  # transformador personalizado\n",
    "        ('imputerc', SimpleImputer(strategy=\"most_frequent\")),    \n",
    "        ('encoder', OneHotEncoder(sparse=False)), \n",
    "    ])\n",
    "\n",
    "    #Aplicar los transformer a nuestras features usando ColumnTransformer, es nuestro pre-procesamiento.\n",
    "    # Ojo se van a cambiar las letra inicial a capital de Disloyal?, se hace en un pipeline? Se deja arreglado\n",
    "    # en la encuesta\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "           ('numeric', num_transformer, num_cols),\n",
    "           ('categorical', cat_transformer, cat_cols)\n",
    "        ])\n",
    "    \n",
    "    #PIPELINE\n",
    "    # Estimator o modelo a aplicar\n",
    "    pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('modelo', model)\n",
    "    ])\n",
    "    \n",
    "    # Validación cruzada\n",
    "    cv_results = cross_validate(pipeline, X, y, cv=3, scoring='accuracy')\n",
    "    \n",
    "     # Métricas\n",
    "    train_scores = cv_results['train_score']\n",
    "    test_scores = cv_results['test_score']\n",
    "     \n",
    "     # Imprimir resultados\n",
    "    print(f\"Train Scores: {train_scores}\")\n",
    "    print(f\"Test Scores: {test_scores}\")\n",
    "    print(f\"Mean Train Score: {train_scores.mean()}\")\n",
    "    print(f\"Mean Test Score: {test_scores.mean()}\")\n",
    "       \n",
    "    \n",
    "    \n",
    "    if flag:\n",
    "        # Guardar el pipeline usando Pickle. Por qué  lo estoy guardando aquí?\n",
    "        with open('data_pipeline.pkl', 'wb') as file:\n",
    "            pickle.dump(pipeline, file)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(model, flag):\n",
    "  \n",
    "\n",
    "    # Transformador para la columna 'Arrival Delay in Minutes'\n",
    "    #delay_transformer = FunctionTransformer(func=to_int)\n",
    "    \n",
    "    # Transformador para la columna 'Customer Type' para CamelCase\n",
    "    #customer_transformer = FunctionTransformer(func=camel_case)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #num_transformer = Pipeline(steps=[\n",
    "    #('delay_to_int', delay_transformer),      \n",
    "    #('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "    #('scaler', MinMaxScaler())\n",
    "   # ])\n",
    "\n",
    "    ##cat_transformer = Pipeline(steps=[\n",
    "        #('correct_disloyal', customer_transformer(column_name='Customer Type')),  # transformador personalizado\n",
    "        #('imputerc', SimpleImputer(strategy=\"most_frequent\")),    \n",
    "        #('encoder', OneHotEncoder(sparse=False)), \n",
    "    #])\n",
    "\n",
    "    #Aplicar los transformer a nuestras features usando ColumnTransformer, es nuestro pre-procesamiento.\n",
    "    # Ojo se van a cambiar las letra inicial a capital de Disloyal?, se hace en un pipeline? Se deja arreglado\n",
    "    # en la encuesta\n",
    "\n",
    "    #preprocessor = ColumnTransformer(\n",
    "        #transformers=[\n",
    "           #('numeric', num_transformer, num_cols),\n",
    "           #('categorical', cat_transformer, cat_cols)\n",
    "        #])\n",
    "    \n",
    "    \n",
    "    # Estimator o modelo a aplicar\n",
    "    #pipeline = Pipeline(steps = [\n",
    "        #('preprocessor', preprocessor),\n",
    "        #('modelo', model)\n",
    "    #])\n",
    "    \n",
    "    \n",
    "    # Aplicar el pipeline a los datos de entrenamiento\n",
    "    #pipeline.fit(X_train, y_train) # ESte está correcto.\n",
    "    #pipeline.fit(X, y_train) # ESte está correcto\n",
    "    \n",
    "    # Obtiene las predicciones del modelo en los datos de entrenamiento\n",
    "    #y_train_pred = pipeline.predict(X_train)\n",
    "       \n",
    "    # Preprocesa (transforma) los datos de prueba\n",
    "    #X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "    # Obtiene las predicciones del modelo en los datos de prueba transformados\n",
    "    #y_test_pred = pipeline.named_steps['modelo'].predict(X_test_transformed)\n",
    "    \n",
    "    \n",
    "    #if flag:\n",
    "        # Guardar el pipeline usando Pickle. Por qué  lo estoy guardando aquí?\n",
    "        #with open('data_pipeline.pkl', 'wb') as file:\n",
    "            #pickle.dump(pipeline, file)\n",
    "    \n",
    "    # ********************** Calcula Métricas ********************************\n",
    "        \n",
    "    #a = accuracy_score(y_train,y_train_pred)*100\n",
    "    #b = accuracy_score(y_test,y_test_pred)*100\n",
    "    \n",
    "    #training_score.append(a)\n",
    "    #testing_score.append(b)\n",
    "    \n",
    "    #print(f\"Accuracy_Score of {model} model on Training Data is:\",a)\n",
    "    #print(f\"Accuracy_Score of {model} model on Testing Data is:\",b)\n",
    "    \n",
    "    #print(\"\\n------------------------------------------------------------------------\")\n",
    "    #print(f\"Precision Score of {model} model is:\",precision_score(y_test,y_test_pred, pos_label='satisfied'))\n",
    "    #print(f\"Recall Score of {model} model is:\",recall_score(y_test,y_test_pred, pos_label='satisfied'))\n",
    "    #print(f\"F1 Score of {model} model is:\",f1_score(y_test,y_test_pred, pos_label='satisfied'))\n",
    "    #print(\"\\n------------------------------------------------------------------------\")\n",
    "    #print(f\"Confusion Matrix of {model} model is:\")\n",
    "    #cm = confusion_matrix(y_test,y_test_pred)\n",
    "    #plt.figure(figsize=(8,4))\n",
    "    #sns.heatmap(cm,annot=True,fmt=\"g\",cmap=\"summer\")\n",
    "    #plt.show()\n",
    "    \n",
    "    #return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEPARACION DE CARACTERISTICAS Y VARIABLE OBJETIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Age\",\"Flight Distance\",\"Inflight wifi service\",\"Departure/Arrival time convenient\", \"Ease of Online booking\",\n",
    "                 \"Gate location\", \"Food and drink\", \"Online boarding\", \"Seat comfort\", \"Inflight entertainment\", \"On-board service\",\n",
    "                 \"Leg room service\", \"Baggage handling\", \"Checkin service\", \"Inflight service\", \"Cleanliness\", \"Departure Delay in Minutes\",\n",
    "                 \"Arrival Delay in Minutes\"]\n",
    "\n",
    "cat_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar Variable Objetivo, target o variable dependiente de las variables independientes\n",
    "df_f = pd.DataFrame(df)\n",
    "y = df_f[\"satisfaction\"]\n",
    "X = df_f.drop(columns=\"satisfaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido los dataset en training y test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas categóricas y numéricas. \n",
    "#num_cols = ['Inflight wifi service', 'Food and drink']\n",
    "#cat_cols = ['Customer Type', 'Gender'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los mejores parámetros (estos parametros se definieron ya habiendo corrido\n",
    "# la sigueinte linea de cosigo que buscaron los mejores parametros)\n",
    "best_params = {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}\n",
    "\n",
    "# Crear un modelo de Gradient Boosting con los mejores parámetros\n",
    "gb_model = GradientBoostingClassifier(**best_params)\n",
    "\n",
    "# Crear el pipeline que combina el preprocesador y el modelo.\n",
    "#pipeline = Pipeline(steps=[\n",
    "#    ('preprocessor', preprocessor),\n",
    "#    ('gradient_boosting', gb_model)\n",
    "#])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUSQUEDA DE HIPERPARAMETROS\n",
    "\n",
    "Con este codigo se buscaron los mejores hiperparametro los cuales se utilizan y ya se comenta para no tener que usar mas esta linea de codigo y poner mas lento el programa.\n",
    "\n",
    "Best Gradient Boosting Model - Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la cuadrícula de hiperparámetros a explorar\n",
    "# param_grid = {\n",
    "    #'n_estimators': [50, 100, 150],\n",
    "    #'learning_rate': [0.01, 0.1, 0.2],\n",
    "    #'max_depth': [3, 5, 7]\n",
    "\n",
    "# Realizar Grid Search con validación cruzada\n",
    "#grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "#grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y el mejor modelo\n",
    "# best_params = grid_search.best_params_\n",
    "# best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "# print(\"Best Gradient Boosting Model - Best Params:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A continuación, podemos usar el pipeline para entrenar y evaluar tu modelo.\n",
    "Por ejemplo, puedes ajustar el pipeline a tus datos de entrenamiento y realizar predicciones:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBANDO MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir listas para almacenar los puntajes de precisión\n",
    "training_score = []  # Lista para puntajes de precisión en datos de entrenamiento\n",
    "testing_score = []   # Lista para puntajes de precisión en datos de prueba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probamos los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-Validation Llamada a la función\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred(LogisticRegression(solver= 'liblinear',penalty='l1', X, y, save_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_pred(LogisticRegression(solver= 'liblinear',penalty='l1'), save_pickle)\n",
    "#model_prediction(LogisticRegression(solver= 'liblinear',penalty='l1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier\n",
    "model_pred(KNeighborsClassifier(), save_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred(AdaBoostClassifier(n_estimators=200,  random_state=1), save_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación de los modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(training_score)\n",
    "print(testing_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Logistic Regression\",\"KNN\",\"Ada Boos Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame({\"Algorithms\":models,\n",
    "                   \"Training Score\":training_score,\n",
    "                   \"Testing Score\":testing_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar con todos los datos al modelo escogido\n",
    "#### Guardar el pickle ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que escogemos AdaBoostClassifier. Volvemos a llamar a la función model_pred()\n",
    "\n",
    "# Flag que indica, cuando es True, que es la última vez que se entrena al modelo definitivo y se puede guardar\n",
    "save_pickle = True \n",
    "model_pred(AdaBoostClassifier(n_estimators=200,  random_state=1), save_pickle)\n",
    "save_pickle = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE CORRELACION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION\n",
    "\n",
    "- Edad: La edad tiene una correlación positiva débil (0.137) con la satisfacción. Esto sugiere que los pasajeros mayores tienden a estar ligeramente más satisfechos en comparación con los pasajeros más jóvenes.\n",
    "- Distancia del Vuelo (Flight Distance): La distancia del vuelo tiene una correlación negativa moderada (-0.299) con la satisfacción. Esto indica que a medida que la distancia del vuelo aumenta, la satisfacción tiende a disminuir. Los vuelos más largos podrían estar asociados con niveles de satisfacción más bajos.\n",
    "  \n",
    "- Embarque en Línea (Online Boarding): La variable \"Online Boarding\" tiene una correlación negativa fuerte (-0.503) con la satisfacción. Esto significa que los pasajeros que tienen una experiencia de embarque en línea mejor tienden a estar más satisfechos con el servicio.\n",
    "  \n",
    "- Comodidad del Asiento (Seat Comfort): La comodidad del asiento tiene una correlación positiva fuerte (0.349) con la satisfacción. Los pasajeros que encuentran cómodos los asientos tienden a estar más satisfechos.\n",
    "\n",
    "- Entretenimiento a Bordo (Inflight Entertainment): El entretenimiento a bordo tiene una correlación positiva fuerte (0.398) con la satisfacción. Los pasajeros que disfrutan del entretenimiento a bordo tienden a estar más satisfechos.\n",
    "\n",
    "- Limpieza (Cleanliness): La limpieza tiene una correlación positiva moderada (0.305) con la satisfacción. Los pasajeros que perciben que la cabina está limpia tienden a estar más satisfechos.\n",
    "  \n",
    "- Clase (Class): La clase de vuelo también tiene una influencia en la satisfacción. La variable \"Class_Eco\" tiene una correlación negativa moderada con la satisfacción, mientras que \"Class_Business\" tiene una correlación positiva moderada. Esto sugiere que los pasajeros de clase económica pueden estar menos satisfechos en comparación con los pasajeros de clase business.\n",
    "  \n",
    "- Tipo de Viaje (Type of Travel): La variable \"Type of Travel_Personal Travel\" tiene una correlación negativa moderada con la satisfacción, lo que sugiere que los viajes de negocios podrían estar asociados con niveles de satisfacción más altos en comparación con los viajes personales.\n",
    "  \n",
    "- Tipo de Cliente (Customer Type): La variable \"Customer Type_Loyal Customer\" tiene una correlación positiva moderada con la satisfacción, lo que sugiere que los clientes leales tienden a estar más satisfechos.\n",
    "  \n",
    "- Tiempo de Llegada y Salida Conveniente (Departure/Arrival Time Convenient): Esta característica tiene una correlación positiva débil (0.052) con la satisfacción. Los pasajeros que consideran que el tiempo de llegada y salida es conveniente tienden a estar ligeramente más satisfechos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
