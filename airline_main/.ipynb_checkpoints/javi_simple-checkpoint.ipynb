{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02273e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, make_scorer\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, X, y):  \n",
    "   \n",
    "    # Define a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                    ('scaler', MinMaxScaler())]), num_cols),\n",
    "            ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))]), cat_cols)])\n",
    "\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('model', model)])\n",
    "\n",
    "    # Define the metrics for evaluation\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1': make_scorer(f1_score, average='weighted'),\n",
    "        'recall': make_scorer(recall_score, average='weighted'),\n",
    "        'precision': make_scorer(precision_score, average='weighted')\n",
    "    }\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_results = cross_validate(pipeline, X, y, cv=5, scoring=scoring, return_train_score=True)\n",
    "\n",
    "    # Calculate overfitting as the difference between training and validation accuracy\n",
    "    overfitting = np.mean(cv_results['train_accuracy']) - np.mean(cv_results['test_accuracy'])\n",
    "\n",
    "    # Store the evaluation results\n",
    "    results = {\n",
    "        'fit_time': np.mean(cv_results['fit_time']),\n",
    "        'accuracy': np.mean(cv_results['test_accuracy']),\n",
    "        'f1': np.mean(cv_results['test_f1']),\n",
    "        'recall': np.mean(cv_results['test_recall']),\n",
    "        'precision': np.mean(cv_results['test_precision']),\n",
    "        'overfitting': overfitting\n",
    "    }\n",
    "\n",
    "    # Train the model on the entire dataset\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8674ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'airline_passenger_satisfaction.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing steps\n",
    "# Drop unnecessary columns\n",
    "df.drop(['Unnamed: 0', 'id'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values and type conversions\n",
    "df['Arrival Delay in Minutes'].fillna(0, inplace=True)\n",
    "df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].astype(int)\n",
    "df['Customer Type'] = df['Customer Type'].replace('disloyal Customer', 'Disloyal Customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2302eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variables\n",
    "X = df.drop('satisfaction', axis=1)\n",
    "y = df['satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69aa7d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns\n",
    "num_cols = [col for col in X.columns if (X[col].dtype == 'int64' or X[col].dtype == 'int32')]\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5f66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    # Agrega otros modelos aquí\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd0e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un diccionario para almacenar los resultados de cada modelo\n",
    "resultados_por_modelo = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6a385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para el modelo LogisticRegression:\n",
      "fit_time: 0.8514237403869629\n",
      "accuracy: 0.8750289112004891\n",
      "f1: 0.8746956074908748\n",
      "recall: 0.8750289112004891\n",
      "precision: 0.8749083194270094\n",
      "overfitting: 0.0002044802325990025\n",
      "==================================================\n",
      "Resultados para el modelo RandomForestClassifier:\n",
      "fit_time: 9.984806251525878\n",
      "accuracy: 0.9625038632173955\n",
      "f1: 0.9624255271032773\n",
      "recall: 0.9625038632173955\n",
      "precision: 0.9627309507167137\n",
      "overfitting: 0.03749373070967643\n",
      "==================================================\n",
      "Resultados para el modelo KNeighborsClassifier:\n",
      "fit_time: 0.32404370307922364\n",
      "accuracy: 0.9279142687856341\n",
      "f1: 0.9275026334108258\n",
      "recall: 0.9279142687856341\n",
      "precision: 0.9292267744888367\n",
      "overfitting: 0.019919790003117166\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Itera sobre los modelos\n",
    "for modelo in modelos:\n",
    "    # Entrena y evalúa el modelo actual\n",
    "    resultados = train_and_evaluate_model(modelo, X, y)\n",
    "    \n",
    "    # Almacena los resultados en el diccionario\n",
    "    nombre_modelo = type(modelo).__name__\n",
    "    resultados_por_modelo[nombre_modelo] = resultados\n",
    "\n",
    "# Imprime los resultados para cada modelo\n",
    "for nombre_modelo, resultados in resultados_por_modelo.items():\n",
    "    print(f\"Resultados para el modelo {nombre_modelo}:\")\n",
    "    for metrica, valor in resultados.items():\n",
    "        print(f\"{metrica}: {valor}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc2732f",
   "metadata": {},
   "source": [
    "## Significado de los warning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfe448",
   "metadata": {},
   "source": [
    "El mensaje de advertencia que estás viendo se refiere a que el modelo de regresión logística no pudo converger con los hiperparámetros predeterminados que estás utilizando. Esto significa que el algoritmo no pudo encontrar los coeficientes óptimos para el modelo logístico dentro del número máximo de iteraciones permitidas.\n",
    "\n",
    "Para abordar este problema, puedes probar las siguientes soluciones:\n",
    "\n",
    "Aumentar el número máximo de iteraciones: Puedes aumentar el número máximo de iteraciones permitidas para permitir que el algoritmo tenga más tiempo para converger. Esto se hace configurando el hiperparámetro max_iter en el modelo de regresión logística. Por ejemplo, puedes establecer max_iter=1000:\n",
    "\n",
    "Escalar las características: La convergencia puede ser un problema si las características tienen diferentes escalas. Escalar las características a un rango similar, como lo estás haciendo con MinMaxScaler en las características numéricas, puede ayudar a mejorar la convergencia. Asegúrate de que todas las características numéricas estén siendo escaladas de manera adecuada.\n",
    "\n",
    "Explorar otros solucionadores: El mensaje de advertencia también sugiere explorar otros solucionadores. Puedes probar diferentes solucionadores pasando el argumento solver al modelo de regresión logística.\n",
    "\n",
    "'Logistic_Regression': LogisticRegression(solver='saga', max_iter=1000),\n",
    "\n",
    "El solucionador 'saga' es una opción que puede funcionar bien en conjuntos de datos grandes y puede ser más robusto en términos de convergencia.\n",
    "\n",
    "Regularización: Puedes agregar regularización al modelo de regresión logística para ayudar en la convergencia. Esto se hace a través de los hiperparámetros penalty (por ejemplo, 'l2' para la regularización L2) y C (la fuerza de la regularización). Experimenta con diferentes valores de C para ver cómo afecta a la convergencia.\n",
    "\n",
    "Recuerda que es importante realizar una validación cruzada y ajustar los hiperparámetros adecuadamente para obtener el mejor rendimiento del modelo de regresión logística en tu conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3132e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
